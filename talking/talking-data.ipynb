{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ip:** ip address of click.  \n",
    "**app:** app id for marketing.  \n",
    "**device:** device type id of user mobile phone (e.g., iphone 6 plus, iphone 7, huawei mate 7, etc.)  \n",
    "**os:** os version id of user mobile phone  \n",
    "**channel:** channel id of mobile ad publisher  \n",
    "**click_time:** timestamp of click (UTC)  \n",
    "**attributed_time:** if user download the app for after clicking an ad, this is the time of the app download  \n",
    "**is_attributed:** the target that is to be predicted, indicating the app was downloaded  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    dtype = {\n",
    "        \"ip\":\"category\",\n",
    "        \"app\":\"category\",\n",
    "        \"device\":\"category\",\n",
    "        \"os\":\"category\",\n",
    "        \"channel\":\"category\",\n",
    "        \"click_time\":\"str\",\n",
    "        \"attributed_time\":\"str\",\n",
    "        \"is_attributed\":\"int\"\n",
    "    }\n",
    "    parse_dates=['click_time','attributed_time']\n",
    "    return dd.read_csv('train_sample.csv',dtype=dtype,parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    dtype = {\n",
    "        \"click_id\":\"category\",\n",
    "        \"app\":\"category\",\n",
    "        \"device\":\"category\",\n",
    "        \"os\":\"category\",\n",
    "        \"channel\":\"category\",\n",
    "        \"click_time\":\"str\"\n",
    "    }\n",
    "    parse_dates=['click_time']\n",
    "    return dd.read_csv('test.csv',dtype=dtype,parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_train()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_test()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN DATASET\n",
    "train['click_rnd'] = train.click_time.dt.round('H')\n",
    "train['hour']      = train.click_time.dt.hour.astype('category')\n",
    "train['day']      = train.click_time.dt.day.astype('category')\n",
    "train['month']    = train.click_time.dt.month.astype('category')\n",
    "train['year']     = train.click_time.dt.year.astype('category')\n",
    "train['weekday']  = train.click_time.dt.weekday.astype('category')\n",
    "\n",
    "#TEST DATASET\n",
    "test['click_rnd'] = test.click_time.dt.round('H')\n",
    "test['hour']      = test.click_time.dt.hour.astype('category')\n",
    "test['day']      = test.click_time.dt.day.astype('category')\n",
    "test['month']    = test.click_time.dt.month.astype('category')\n",
    "test['year']     = test.click_time.dt.year.astype('category')\n",
    "test['weekday']  = test.click_time.dt.weekday.astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attributed_by_month = train.groupby(['month','is_attributed']).count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attributed_by_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA - EXPLORATORY DATA ANALISYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(12,5)});\n",
    "plt.figure(figsize=(12,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "cols = ['ip', 'app', 'device', 'os', 'channel','year','month','weekday','day','hour']\n",
    "uniques = [len(train[col].unique()) for col in cols]\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.barplot(cols, uniques, log=True)\n",
    "ax.set(xlabel='Feature', ylabel='log(unique count)', title='Number of unique values per feature (from 10,000,000 samples)')\n",
    "for p, uniq in zip(ax.patches, uniques):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,height + 10,uniq,ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.set(font_scale=1.2)\n",
    "mean = (train.is_attributed.values == 1).mean()\n",
    "ax = sns.barplot(['App Downloaded (1)', 'Not Downloaded (0)'], [mean, 1-mean])\n",
    "ax.set(ylabel='Proportion', title='App Downloaded vs Not Downloaded')\n",
    "for p, uniq in zip(ax.patches, [mean, 1-mean]):\n",
    "    height = p.get_height()\n",
    "    T = uniq.all\n",
    "    ax.text(p.get_x() + p.get_width()/2., height + 0.01,'{0:.2f}%'.format(uniq.compute() * 100),ha=\"center\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['click_rnd','is_attributed']].groupby(['click_rnd']).count().compute().plot()\n",
    "plt.title('HOURLY CLICK FREQUENCY');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['click_rnd','is_attributed']].groupby(['click_rnd']).mean().compute().plot()\n",
    "plt.title('HOURLY CONVERSION RATIO');\n",
    "plt.ylabel('Converted Ratio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weekday']= train['weekday'].astype('category')\n",
    "train[['weekday','is_attributed']].groupby(['weekday']).mean().compute().plot()\n",
    "plt.title('WEEKDAY CONVERSION RATIO');\n",
    "plt.ylabel('Converted Ratio');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = train['is_attributed']\n",
    "d_train = train.drop(['is_attributed', 'attributed_time','click_rnd','click_time'], axis=1)\n",
    "\n",
    "\n",
    "sub = test['click_id']\n",
    "d_test = test.drop(['click_id','click_rnd','click_time'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask-ml[complete] \n",
    "d_train.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train.ip = d_train.ip.astype(int)\n",
    "d_train.app = d_train.app.astype(int)\n",
    "d_train.device = d_train.device.astype(int)\n",
    "d_train.os = d_train.os.astype(int)\n",
    "d_train.channel = d_train.channel.astype(int)\n",
    "d_train.hour = d_train.hour.astype(int)\n",
    "d_train.day = d_train.day.astype(int)\n",
    "d_train.month = d_train.month.astype(int)\n",
    "d_train.year = d_train.year.astype(int)\n",
    "d_train.weekday = d_train.weekday.astype(int)\n",
    "\n",
    "\n",
    "d_test.ip = d_test.ip.astype(int)\n",
    "d_test.app = d_test.app.astype(int)\n",
    "d_test.device = d_test.device.astype(int)\n",
    "d_test.os = d_test.os.astype(int)\n",
    "d_test.channel = d_test.channel.astype(int)\n",
    "d_test.hour = d_test.hour.astype(int)\n",
    "d_test.day = d_test.day.astype(int)\n",
    "d_test.month = d_test.month.astype(int)\n",
    "d_test.year = d_test.year.astype(int)\n",
    "d_test.weekday = d_test.weekday.astype(int)\n",
    "\n",
    "\n",
    "#ip, app, device, os, channel, hour, day, month, year, weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x1, x2, y1, y2 = train_test_split(d_train.compute(), y.compute(), test_size=0.1, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.5367431640625e-05] Start XGBoost Training\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bb0c83537b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m270\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print('[{}] Start XGBoost Training'.format(time.time() - start_time))\n",
    "\n",
    "params = {'eta': 0.1, \n",
    "          'max_depth': 4, \n",
    "          'subsample': 0.9, \n",
    "          'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':100,\n",
    "          'alpha':4,\n",
    "          'objective': 'binary:logistic', \n",
    "          'eval_metric': 'auc', \n",
    "          'random_state': 99, \n",
    "          'scale_pos_weight': 150,\n",
    "          'silent': True}\n",
    "\n",
    "\n",
    "watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "model = xgb.train(params, xgb.DMatrix(x1, y1), 270, watchlist, maximize=True, verbose_eval=10)\n",
    "\n",
    "print('[{}] Finish XGBoost Training'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub['is_attributed'] = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n",
    "sub.to_csv('xgb_sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDEIAS\n",
    "\n",
    "1 - usar algoritmos evolucion√°rios para o tunning de hyperparametros  \n",
    "2 - dropar o ip  \n",
    "3 - comparar os dados do dataset de treinamento e teste\n",
    "4 - rodar LightGBM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/yuliagm/talkingdata-eda-plus-time-patterns  \n",
    "https://www.kdnuggets.com/2016/08/include-high-cardinality-attributes-predictive-model.html  \n",
    "https://www.theanalysisfactor.com/3-situations-when-it-makes-sense-to-categorize-a-continuous-predictor-in-a-regression-model/  \n",
    "https://www.kaggle.com/pranav84/lightgbm-fixing-unbalanced-data-val-auc-0-977/comments  \n",
    "https://www.kaggle.com/pranav84/xgboost-on-hist-mode-ip-addresses-dropped/code  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
